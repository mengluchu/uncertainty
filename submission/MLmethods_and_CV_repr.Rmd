---
title: "cross validation"
output:
  html_document:
    df_print: paged
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path=paste0('global_crossvali',"/"),
                      echo=F, warning=FALSE, message=FALSE, dev = "png", include = T)
```
 
Required packages
```{r, include=F}
ipak <- function(pkg){
 
   new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
   if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
  sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "xgboost",  "glmnet", "ranger", "randomForest","tidyr" ,"tibble","stargazer", "sf",   "quantregForest", "pdp", "h2o", "dismo","scoringRules")
ipak(packages)
install_github("mengluchu/APMtools") 
library(APMtools)
ls("package:APMtools") 

```

Variables used:
```{r}
resolution =1 # resolution of grid
nboot = 1  # number of bootstraps
y_var = "mean_value"
prestring =  "road|nightlight|population|temp|wind|trop|indu|elev|radi"
varstring = paste(prestring,y_var,sep="|")
```

Prepare the dataset for modeling 

```{r}
mergedall = read.csv("https://raw.githubusercontent.com/mengluchu/uncertainty/master/data_vis_exp/DENL17_uc.csv")

if (resolution ==100)
{
  mergedall = mergedall%>%dplyr::select(-c(industry_25,industry_50,road_class_1_25,road_class_1_50,road_class_2_25,road_class_2_50,   road_class_3_25,road_class_3_50))
}  

merged = mergedall%>%dplyr::select(matches(varstring))%>% na.omit() # there is actually no na in this file, but for now RF and LA doesnt deal with missing data, leave out for quick examination 
 
 
names(merged)
```  

Data summary
```{r, eval=FALSE} 
mergedall$AirQualityStationArea%>%table
mergedall$AirQualityStationType%>%table
 
mergedall%>%filter(AirQualityStationType=="traffic")%>%dplyr::select(wkd_day_value)%>%summary
mergedall%>%filter(AirQualityStationType=="traffic")%>%dplyr::select(wkd_night_value)%>%summary
mergedall%>%filter(AirQualityStationType=="background")%>%dplyr::select(wkd_day_value)%>%summary
mergedall%>%filter(AirQualityStationType=="background")%>%dplyr::select(wkd_night_value)%>%summary
```
 



Use H2o for kfold CV and get predictions.
Initialize h2o, requires Java and JDK to be installed. 

```{r, eval=FALSE}
h2o.init()

x_var = setdiff(names(merged), y_var)
merged_hex = as.h2o(merged)
rf = h2o.randomForest(y = y_var, x= x_var, training_frame = merged_hex, ntrees =2000,  nfolds =10, keep_cross_validation_predictions = T, seed =1 )

# CV
xgb = h2o.xgboost(y = y_var, x= x_var, training_frame = merged_hex, nfolds =10, ,ntrees =3000, eta =  0.007, subsample = 0.7, max_depth = 6, gamma = 5, reg_lambda =2, reg_alpha = 0, keep_cross_validation_predictions = T, seed =1 )
 
las = h2o.glm(y = y_var, x= x_var, training_frame = merged_hex, alpha = 1,  nfolds =10, keep_cross_validation_predictions = T, seed =1 )

ensemble = h2o.stackedEnsemble(y = y_var, x= x_var, training_frame = merged_hex, base_models = c(rf, xgbl, las))

get_h2o_pred = function(h2omodel) 
{
 cvpreds_id  = h2omodel@model$cross_validation_holdout_predictions_frame_id$name
 as.data.frame(h2o.getFrame(cvpreds_id))$predict
 }
 
 
rf10f_pre =get_h2o_pred(rf)
xgb10f_pre =get_h2o_pred(xgb)
lasso10f_pre =get_h2o_pred(las)  

h2o.removeAll()
# model and predict on all the data

rf_all = h2o.randomForest(y = y_var, x= x_var, training_frame = merged_hex, ntrees =2000, seed =1 )

rf_all_pre = as.data.frame(h2o.predict(object = rf_all, newdata = merged_hex))$predict 

xgb_all = h2o.xgboost(y = y_var, x= x_var, training_frame = merged_hex ,ntrees =3000, eta =  0.007, subsample = 0.7, max_depth = 6, gamma = 5, reg_lambda =2, reg_alpha = 0, seed =1 )

xgb_all_pre = as.data.frame(h2o.predict(object = xgb_all, newdata = merged_hex))$predict 
  
las_all = h2o.glm(y = y_var, x= x_var, training_frame = merged_hex, alpha = 1,   seed=1 )

lasso_all_pre = as.data.frame(h2o.predict(object = las_all, newdata = merged_hex))$predict 
h2o.removeAll()
# check
cor(rf10f_pre,xgb10f_pre)
cor(xgb10f_pre,lasso10f_pre)
plot(mergedall$mean_value, lasso10f_pre)
plot(xgb10f_pre,xgb_all_pre)

```

Add predictions to the csv file 
```{r, eval = F}
addpre = cbind(mergedall,rf10f_pre,xgb10f_pre,lasso10f_pre,rf_all_pre,xgb_all_pre,lasso_all_pre)
write.csv(addpre, "~/Documents/GitHub/uncertainty/data_vis_exp/DENL17_uc.csv")
```

sf object of data, for visualization and spatial cross-validation
```{r}
locations_sf = st_as_sf(mergedall, coords = c("Longitude","Latitude"), crs=4642)
```

Variable importance of Lasso
```{r, eval  = F}
LA_imp =  function(n,df, y_var) {
  smp_size <- floor(0.8 * nrow(df)) 
  set.seed(n)
  training<- sample(seq_len(nrow(df)), size = smp_size)
   
  y_varname= y_var
  grepstring =varstring
  variabledf = df
  prenres = paste(y_varname, "|", grepstring, sep = "")
  pre_mat_all = subset_grep(variabledf, prenres)
  pre_mat = pre_mat_all %>% dplyr::select(-y_varname)
  pre_mat_tr = pre_mat[training, ]
  y_tr_value = variabledf[training, y_varname] 
  cvfit <- glmnet::cv.glmnet(as.matrix(pre_mat_tr), y_tr_value, 
        type.measure = "mse", standardize = TRUE, alpha = 1, 
        lower.limit = 0)
    
  Lassoselected(cvfit)
} 
  VLA = sapply(1:nboot, df = merged,   y_var = y_var, LA_imp)
 
  a= table(do.call(c,VLA))  
  #a =a[a>=5]  
  a = a[order(a,decreasing = T)]
  stargazer(data.frame(a),summary = F)
```
 
Variable importance of ML methods: 20-times bootstrapping
```{r, eval=F}
Impor_val =  function(n,df, method , y_var  ) {

  set.seed(n)
  smp_size <- floor(0.8 * nrow(df))

training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training] 
 
 
methodID = switch(method,  "xboost"=1,"rf" =2 ) 

df = switch(methodID,  
            xgboost_imp (variabledf= df, y_varname= y_var, max_depth =6, gamma=5, eta =0.007, nrounds = 3000, training=training, test=test, grepstring =varstring, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7),  
            rf_imp(df, y_varname= y_var, training=training, test=test, grepstring =varstring,mtry = NULL, numtrees = 2000) 
) 
return(df)
} 
 Vxb = data.frame(lapply(1:20, Impor_val, df= merged, "xboost" , y_var =y_var))
 Vrf = data.frame(lapply(1:20, Impor_val, df = merged, "rf" , y_var = y_var)) 

mimpVrf = apply(Vrf, 1, median)
mimpxb = apply(Vxb, 1, median)
 
 
xb = names(mimpxb[order(mimpxb,decreasing = T)]  )[1:20]
rf = names(mimpVrf[order(mimpVrf,decreasing = T)] ) [1:20]
vimp=cbind(rank = 1:nboot, xgboost = xb, randomforest = rf)
#install.packages("stargazer")
 
stargazer(vimp)
```



Bootstrapped cross-validation 

XGB
```{r xgb, eval=T}
xgb_crossvali =  function(n,df, y_var,typecrossvali = "crossvalinotspatial",coordi = c(mergedall$Longitude, mergedall$Latitude)) {
  smp_size = floor(0.2* nrow(df)) 
  set.seed(n)
  if(typecrossvali == "crossvalinotspatial"){
    test<- sample(seq_len(nrow(df)), size = smp_size)
  }
  if(typecrossvali == "crossvalispatial"){
    # The validation data needs to spatially represent the whole region where the prevalence is predicted
    # We use locations of a spatially representative sample of the prediction surface
    # To obtain a valid data set, X% of the observations are sampled without replacement where
    # each observation has a probability of selection proportional to the area of the Voronoi polygon
    # surrounding its location, that is, the area closest to the location relative to the surrounding points
    p <- matrix(coordi, ncol = 2)
    v <- dismo::voronoi(p) # extent?
    prob_selection <- area(v)/sum(area(v))
   test <- sample(seq_len(nrow(df)), size = smp_size, prob = prob_selection, replace = T)
  }
  training = seq_len(nrow(df))[-test] 
  
  xgboost_LUR(df, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds =1000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7 )
} 


V2 = lapply(1:nboot, df = merged, y_var = y_var,xgb_crossvali)
V2 = data.frame(XGB = rowMeans(data.frame(V2)))
V2
```

RF

```{r, eval = T}
rf_crossvali =  function(n,df, y_var, coordi = c(mergedall$Longitude, mergedall$Latitude), typecrossvali = "crossvalinotspatial") {
  smp_size <- floor(0.2 * nrow(df)) 
  set.seed(n)
  if(typecrossvali == "crossvalinotspatial"){
    test <- sample(seq_len(nrow(df)), size = smp_size)
  }
  if(typecrossvali == "crossvalispatial"){
    # The validation data needs to spatially represent the whole region where the prevalence is predicted
    # We use locations of a spatially representative sample of the prediction surface
    # To obtain a valid data set, X% of the observations are sampled without replacement where
    # each observation has a probability of selection proportional to the area of the Voronoi polygon
    # surrounding its location, that is, the area closest to the location relative to the surrounding points
     
    p <- matrix(coordi, ncol = 2)
    v <- dismo::voronoi(p) # extent?
    prob_selection <- area(v)/sum(area(v))
    test<- sample(seq_len(nrow(df)), size = smp_size, prob = prob_selection, replace = T)
  }
  training = seq_len(nrow(df))[-test] 
  rf_LUR(df, numtrees =  2000, mtry = NULL, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
} 

 
Vrf = lapply(1:nboot, df = merged, y_var = y_var,rf_crossvali)
Vrf = data.frame(RF = rowMeans(data.frame(Vrf)))
Vrf

#server: combine
```
LA
```{r, eval=T}
LA_crossvali =  function(n,df, y_var,typecrossvali = "crossvalinotspatial", coordi = c(mergedall$Longitude, mergedall$Latitude)) {
  smp_size <- floor(0.2 * nrow(df)) 
  set.seed(n)
  if(typecrossvali == "crossvalinotspatial"){
    test <- sample(seq_len(nrow(df)), size = smp_size)
  }
  if(typecrossvali == "crossvalispatial"){
    # The validation data needs to spatially represent the whole region where the prevalence is predicted
    # We use locations of a spatially representative sample of the prediction surface
    # To obtain a valid data set, X% of the observations are sampled without replacement where
    # each observation has a probability of selection proportional to the area of the Voronoi polygon
    # surrounding its location, that is, the area closest to the location relative to the surrounding points
    p <- matrix(c(coordi), ncol = 2)
    v <- dismo::voronoi(p) # extent?
    
    prob_selection <- area(v)/sum(area(v))
    hist(prob_selection, n=500)
    test <- sample(seq_len(nrow(df)), size = smp_size, prob = prob_selection, replace = T)
    tr = p[training,] %>%  sf::st_multipoint() 
    te = p[test,] %>% sf::st_multipoint()
  
  #p = ggplot()+geom_sf(data = te, color = "red")+geom_sf(data=tr)
  #plot(p)
  }
 
  #plot(v)
  training = seq_len(nrow(df))[-test] 
  
 
  
  #p = ggplot()+geom_sf(data = te, color = "red")+geom_sf(data=tr)
  #plot(p)
  Lasso(df, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)
  
  
} 
  VLA = lapply(1:nboot, df = merged, y_var = y_var, LA_crossvali)

  VLA = data.frame(LA = rowMeans(data.frame(VLA)))
  VLA
```
quantiel RF to look at coverage probability.
```{r}
q_rf_crossvali =  function(n,df, y_var,typecrossvali = "crossvalinotspatial", coordi = c(mergedall$Longitude, mergedall$Latitude)) {
  smp_size <- floor(0.2* nrow(df)) 
  set.seed(n)
   if(typecrossvali == "crossvalinotspatial"){
    test <- sample(seq_len(nrow(df)), size = smp_size)
  }
  if(typecrossvali == "crossvalispatial"){
    # The validation data needs to spatially represent the whole region where the prevalence is predicted
    # We use locations of a spatially representative sample of the prediction surface
    # To obtain a valid data set, X% of the observations are sampled without replacement where
    # each observation has a probability of selection proportional to the area of the Voronoi polygon
    # surrounding its location, that is, the area closest to the location relative to the surrounding points
    p <- matrix(coordi, ncol = 2)
    v <- dismo::voronoi(p) # extent?
    prob_selection <- area(v)/sum(area(v))
    test <- sample(seq_len(nrow(df)), size = smp_size, prob = prob_selection, replace = FALSE)
  }
training = seq_len(nrow(df))[-test] 
  q_rf_LUR(df, numtrees =  2000, mtry = NULL,  y_varname= y_var, training=training, test=test, grepstring =varstring)} 
qrf = lapply(1:nboot, df = merged, y_var = y_var, q_rf_crossvali )
 qrf = data.frame(QRF = rowMeans(data.frame(qrf)))
 qrf
```
QRFLA
```{r}
 
rf_la_crossvali =  function(n,df, y_var,typecrossvali = "crossvalinotspatial", coordi = c(mergedall$Longitude, mergedall$Latitude)) {
  smp_size <- floor(0.2* nrow(df)) 
  set.seed(n)
   if(typecrossvali == "crossvalinotspatial"){
    test <- sample(seq_len(nrow(df)), size = smp_size)
  }
  if(typecrossvali == "crossvalispatial"){
    # The validation data needs to spatially represent the whole region where the prevalence is predicted
    # We use locations of a spatially representative sample of the prediction surface
    # To obtain a valid data set, X% of the observations are sampled without replacement where
    # each observation has a probability of selection proportional to the area of the Voronoi polygon
    # surrounding its location, that is, the area closest to the location relative to the surrounding points
    p <- matrix(coordi, ncol = 2)
    v <- dismo::voronoi(p) # extent?
    prob_selection <- area(v)/sum(area(v))
    test <- sample(seq_len(nrow(df)), size = smp_size, prob = prob_selection, replace = FALSE)
  }
 
training = seq_len(nrow(df))[-test] 
result = rf_Lasso_LUR(df, numtrees =  3000, mtry = NULL,  y_varname= y_var, training=training, test=test, grepstring =prestring)
} 
rfla= lapply(1:nboot, df = merged, y_var = y_var,rf_la_crossvali )
rfla = data.frame(RFLA = rowMeans(data.frame(rfla)))
rfla
```

```{r, eval=F}
df = data.frame(Lasso = VLA,RF = Vrf, XGB = V2 , RF_Lasso = rfla)
stargazer(df,summary = F, digits = 2)
```

XGB-G  
```{r}
#n = 1 
#33df = merged 
xgbgamma_cv = function(n,df, y_var){
h2o.init()
 
set.seed(n)
 
smp_size <- floor(0.2 * nrow(df)) 
  
test <- sample(seq_len(nrow(df)), size = smp_size)
training = seq_len(nrow(df))[-test] 
  
x_var = setdiff(names(merged), y_var) # predictor names
 
train_xy = df[training,]
test_xy = df[test,]
y_train = train_xy[, y_var]
y_test = test_xy[, y_var]
x_train = train_xy%>%dplyr::select(x_var)
x_test = test_xy%>%dplyr::select(x_var)

train_hex = as.h2o(train_xy)
test_hex = as.h2o(test_xy)
  

# model and predict on all the data


xgb  = h2o.xgboost(y = y_var, x= x_var, training_frame = train_hex ,ntrees = 1000, eta =  0.007, subsample = 0.7, max_depth = 6, gamma = 5, reg_lambda =2, reg_alpha = 0, seed =1, distribution = "gamma" )

xgb_pre = as.data.frame(h2o.predict(object = xgb, newdata = test_hex))$predict 
h2o.removeAll()
APMtools::error_matrix (validation = y_test, prediction = xgb_pre)
}

rg = lapply(1:nboot, df = merged, y_var = y_var, xgbgamma_cv  )
rg2 = data.frame(XGB_GAMMA = rowMeans(data.frame(rg)))
rg2#gamma
```

```{r resulttable}
df = data.frame(Lasso = VLA,RF = Vrf, XGB = V2, XGB_Gamma =rg2, RF_Lasso = rfla[1:8,])
stargazer(df,summary = F, digits = 2)
```

```{r}
h2o.removeAll()
```


 
 
#### Spatial cross-validation
Sp1 is purely spatial, sp2 and sp3 more specific for air quality, based on the local environment of ground stations. sp2 is easily applicable to the grid.  
- sp1: spatial blocked cv (see R script "SPblock_repr").
- sp2: based on customized predictors (e.g. road_class_2_25>0 && population >1000
 
 
#### SP2 customized
- "tr_hp": close to roads, high population
- "tr_mlp": close to roads, middle-low population 
- "f": far away from roads 

```{r}
source("~/Documents/GitHub/uncertainty/MLmodeling/INLA/INLA_util.R")

INLA_crossvali2 =  function(n, test, training, d, dp, formula, covnames, typecrossvali = "non-spatial", family = "gaussian"){
 
  dtraining = d[training, ]
  dptest = dp[test, ]
 
  lres = fnFitModelINLA(dtraining, dptest, formula, covnames, TFPOSTERIORSAMPLES = FALSE, family = family)
  # Get predictions
  dptest = fnGetPredictions(lres[[1]], lres[[2]], lres[[3]], dtraining, dptest, covnames, NUMPOSTSAMPLES = 0, cutoff_exceedanceprob = 30)
  # Goodness of fit
  val = APMtools::error_matrix(validation = dptest$real, prediction = dptest$pred_mean)
  val = c(val, cor = cor(dptest$real, dptest$pred_mean))
  inlacrps = crps(y =dptest$real, family = "norm", mean = dptest$pred_mean, sd =dptest$pred_sd) 
   
  
  (val = c(val, covprob95 = mean(dptest$pred_ll <= dptest$real &  dptest$real <= dptest$pred_ul),  # 95% coverage probabilities
            covprob90 = mean(dptest$pred_ll90 <= dptest$real &  dptest$real <= dptest$pred_ul90),
            covprob50 = mean(dptest$pred_ll50 <= dptest$real &  dptest$real <= dptest$pred_ul50),
             meancrps = mean(inlacrps),
           mediancrps = median(inlacrps)))
  return(val)
} 

d = read.csv("https://raw.githubusercontent.com/mengluchu/uncertainty/master/data_vis_exp/DENL17_uc.csv")
head(d)
d$y = d$mean_value #     # For GAMMA distribution
d$coox = d$Longitude
d$cooy = d$Latitude
d$b0 = 1 # intercept
d$real = d$y
# Variables for stacked generalization
# d$lasso = d$lasso10f_pre
# d$rf = d$rf10f_pre
# d$xgb = d$xgb10f_pre
d$Countrycode  = as.factor(d$Countrycode)
d$MeasurementType  = as.factor(d$MeasurementType)
d$AirQualityStationType = as.factor(d$AirQualityStationType)
d$AirQualityStationArea = as.factor(d$AirQualityStationArea)
d$urbantype = as.factor(d$urbantype)

# Data for prediction
#dp = d

covnames = c("b0", "nightlight_450", "population_1000", "population_3000", 
             "road_class_1_5000", "road_class_2_100", "road_class_3_300",  
             "trop_mean_filt", "road_class_1_100")

#, "Countrycode",  "urbantype"

formula = as.formula(paste0('y ~ 0 + ', paste0(covnames, collapse = '+'), " + f(s, model = spde)"))

```


```{r}
sp2_cv =  function(n, df_type= c("tr_hp", "tr_mlp", "f") , df_model, y_var, formula_inla=formula,covnames_inla=covnames) {
   
set.seed(n)
a= df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0|road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))  
#traffic_lmpop 
b= df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))   
 
#fartr_highpop
c= df_model%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)))  
print(nrow(a))
print(nrow(b))
print(nrow(c))
#85 65 177

methodID = switch(df_type,  "tr_hp"=1,"tr_mlp" =2,"f"=3  ) 
totest = switch(methodID,a,b,c)

 
others = setdiff(df_model, totest)
orderedall=rbind(totest, others) #order data
nrow(orderedall)

#each time use 7% of the data satisfying with the conditions for testing. 
#test_size = floor(0.07*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test_size = floor(0.07*nrow(df_model)) # 8  is about 6% of traffic, use a consistent size about 2% of data

test = sample(nrow(totest), size = test_size) # sample 20% from e.g. traffic and then use others as training 
training = setdiff(seq_len(nrow(df_model)), test)

XGB = xgboost_LUR(orderedall, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 300, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7) 
RF = rf_LUR(orderedall, numtrees =  1000, mtry = NULL, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
LA = Lasso(orderedall, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)



INLA = INLA_crossvali2(d = orderedall, dp =orderedall, formula = formula_inla, covnames = covnames_inla,   typecrossvali = "non-spatial", family = "gaussian",training=training, test=test)

cbind(LA,RF,XGB,INLA)
}  

tr_hp = lapply(1:nboot, df_type ="tr_hp",  df_model =d, y_var = y_var, sp2_cv)%>%data.frame() 
tr_lmp= lapply(1:nboot, df_type ="tr_mlp", df_model =d, y_var = y_var, sp2_cv)%>%data.frame() 
far= lapply(1:nboot, df_type ="f", df_model =d, y_var = y_var, sp2_cv)%>%data.frame() 


F1 = function(m, pre, f=quote(summary), nvaria) {apply(pre[, seq(m, ncol(pre), by =nvaria)], 1, f)}

nv = 4# number of algorithms.
cv_traffic= data.frame(sapply(1:nv, F1, tr_hp, mean,nv)) 
names(cv_traffic) = paste0(c("LA", "RF", "XGB", "INLA"), "_tr_hp")

cv_bg = data.frame(sapply(1:nv, F1, tr_lmp, mean,nv)) 
names(cv_bg) =  paste0(c("LA", "RF", "XGB", "INLA"),"_tr_lmp")

cv_far = data.frame(sapply(1:nv, F1, far, mean,nv)) 
names(cv_far) =  paste0(c("LA", "RF", "XGB", "INLA"),"_far")
cbind(cv_traffic, cv_bg, cv_far)
```


```{r}

sp2 = cbind(cv_traffic, cv_bg, cv_far)
stargazer(t(sp2), summary = F, digits = 2)
stargazer(t(sp2), summary = F, digits = 1)
```

```{r}
merged

```




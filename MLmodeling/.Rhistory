}
sapply(1:nrow(coord), roadlength, ext, i )
#sapply(1:8, roadlength, ext, i )
}
roadtype = c(2:4)
ext = c(25)
#ext  = c(25, 50, 100, 300,1000, 3000, 5000)
extall = mapply(rep, ext, length(roadtype))%>%as.vector()
a = mapply(allroads,roadtype, ext = extall, coord = coordgh)
1:nrow(coord)
roadlength
roadlength =   function(j, ext, i )
{
single = pollatlon[j,]
wkt = st_as_text(single)
r = read_sf(paste0(dirin,"gap_class_", i, ".gpkg"), layer = "lines", wkt_filter = wkt)
# r=  st_crop(st_geometry(r), st_geometry(single)) # crop cannt be omitted..
r = st_intersection(st_geometry(r), st_geometry(single)) # better use intersection than crop
plot(single)
plot(r[1], add = T)
roadlength
roadlength =   function(j, ext, i )
{
single = pollatlon[j,]
wkt = st_as_text(single)
r = read_sf(paste0(dirin,"gap_class_", i, ".gpkg"), layer = "lines", wkt_filter = wkt)
# r=  st_crop(st_geometry(r), st_geometry(single)) # crop cannt be omitted..
r = st_intersection(st_geometry(r), st_geometry(single)) # better use intersection than crop
plot(single)
plot(r[1], add = T)
sum(st_length(r))%>%as.vector() # road length
}
roadlength =   function(j, ext, i )
{
single = pollatlon[j,]
wkt = st_as_text(single)
r = read_sf(paste0(dirin,"gap_class_", i, ".gpkg"), layer = "lines", wkt_filter = wkt)
# r=  st_crop(st_geometry(r), st_geometry(single)) # crop cannt be omitted..
r = st_intersection(st_geometry(r), st_geometry(single)) # better use intersection than crop
plot(single)
plot(r[1], add = T)
sum(st_length(r))%>%as.vector() # road length
}
roadlength =   function(j, ext, i )
{
single = pollatlon[j,]
wkt = st_as_text(single)
r = read_sf(paste0(dirin,"gap_class_", i, ".gpkg"), layer = "lines", wkt_filter = wkt)
# r=  st_crop(st_geometry(r), st_geometry(single)) # crop cannt be omitted..
r = st_intersection(st_geometry(r), st_geometry(single)) # better use intersection than crop
plot(single)
plot(r[1], add = T)
sum(st_length(r))%>%as.vector() # road length
}
roadlength
i = 1
ext = 25
sapply(1:nrow(coord), roadlength, ext, i )
allroads = function(i,  ext, coordi = coordgh)  {
pol =   st_buffer(coordi, ext)
pollatlon = st_geometry(st_transform(pol, crs = 4326)) # calculate buffer in projected but put back.
roadlength =   function(j, ext, i )
{
single = pollatlon[j,]
wkt = st_as_text(single)
r = read_sf(paste0(dirin,"gap_class_", i, ".gpkg"), layer = "lines", wkt_filter = wkt)
# r=  st_crop(st_geometry(r), st_geometry(single)) # crop cannt be omitted..
r = st_intersection(st_geometry(r), st_geometry(single)) # better use intersection than crop
plot(single)
plot(r[1], add = T)
sum(st_length(r))%>%as.vector() # road length
}
sapply(1:nrow(coordi), roadlength, ext, i )
#sapply(1:8, roadlength, ext, i )
}
roadtype = c(2:4)
ext = c(25)
#ext  = c(25, 50, 100, 300,1000, 3000, 5000)
extall = mapply(rep, ext, length(roadtype))%>%as.vector()
a = mapply(allroads,roadtype, ext = extall, coord = coordgh)
allroads = function(i,  ext, coordi = coordgh)  {
pol =   st_buffer(coordi, ext)
pollatlon = st_geometry(st_transform(pol, crs = 4326)) # calculate buffer in projected but put back.
roadlength =   function(j, ext, i )
{
single = pollatlon[j,]
wkt = st_as_text(single)
r = read_sf(paste0(dirin,"gap_class_", i, ".gpkg"), layer = "lines", wkt_filter = wkt)
# r=  st_crop(st_geometry(r), st_geometry(single)) # crop cannt be omitted..
r = st_intersection(st_geometry(r), st_geometry(single)) # better use intersection than crop
plot(single)
plot(r[1], add = T)
sum(st_length(r))%>%as.vector() # road length
}
sapply(1:8, roadlength, ext, i )
#sapply(1:8, roadlength, ext, i )
}
#ext  = c(25, 50, 100, 300,1000, 3000, 5000)
extall = mapply(rep, ext, length(roadtype))%>%as.vector()
a = mapply(allroads,roadtype, ext = extall, coord = coordgh)
coordi = coordgh
total = nrow(coordi)
total
a
aall[1:8,]
a = mapply(allroads,roadtype, ext = extall, coord = coormoll)
a = mapply(allroads,roadtype, ext = extall, coord = coordmoll)
a = data.frame(a)
a
glo4var[1:8,]
coordgh[3,]
plot( coordgh[3,])
coordsf [3,]
load(spData)
library(spData)
install.packages('spDataLarge', repos='https://nowosad.github.io/drat/', type='source')
library(spDataLarge)
data(world)
names(world)
world[1:2, 2:3]
plot(world[1:2, 2:3])
plot(world[1:2,])
plot(world[,2])
world_asia = world[world$continent == "Asia", ]
asia = st_union(world_asia)
plot(world["pop"], reset = FALSE)
plot(asia, add = TRUE, col = "red")
plot(world["pop"], reset = T)
plot(asia, add = TRUE, col = "red")
plot(world["pop"], reset = T)
plot(asia, add = TRUE, col = "red")
plot(world["pop"], reset = T)
plot(asia, add = TRUE, col = "red")
world["pop"]
plot(world["continent"], reset = FALSE)
cex = sqrt(world$pop) / 10000
world_cents = st_centroid(world, of_largest = TRUE)
plot(st_geometry(world_cents), add = TRUE, cex = cex)
predictors = read.csv ("~/Documents/GitHub/nijmegen/STATION_CSV/metendet_data2020.csv",stringsAsFactors = F)
predictors
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path=paste0('hourly_8',"/"),
echo=F, warning=FALSE, message=FALSE, dev = "pdf", include = T)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" )
ipak(packages)
#install_github("mengluchu/APMtools")
library(APMtools)
y_var = "X8_mean_value"
whichhour= 8
# choose "value_mean for the mean of all hours, for different hours: X9_mean_value, X10_mean_value
sr =  stack("~/Documents/GitHub/nijmegen/predictorsmay20")
prestring =  "road|pop|temp|wind|RSp|OMI|eleva|indu|trop|night"
varstring = paste0(prestring,y_var)
predictors = read.csv ("~/Documents/GitHub/nijmegen/STATION_CSV_483/de_nl_predictors.csv",stringsAsFactors = F)
predictors <- as.data.frame(sapply(predictors, as.numeric))
# no2 measurements
value  = read.csv("~/Documents/Github/nijmegen/STATION_CSV_483/new_DENLjuly.csv", sep = ";")
value
# no2 measurements
value  = read.csv("~/Documents/Github/nijmegen/STATION_CSV_483/new_DENLjuly.csv", sep = ",")
# no2 measurements
value  = read.csv("~/Documents/Github/nijmegen/STATION_CSV_483/new_DENLjuly.csv", sep = ",")
value
value_mean = value%>%dplyr::select(X10_mean_value,X11_mean_value,X7_mean_value,X8_mean_value,X9_mean_value)%>%apply(1,mean)
value_mean
value$value_mean = value_mean
#assign id and merge
value$id = 1:nrow(value)
merged0 = merge(value, predictors, by = "id")
#check
all.equal(merged0$lon.x,merged0$lon.y)
merged0%>%nrow()
nrow(value)
names(value)
summary(value)
summary(value)
summary(merged)
summary(merged0)
table(merged0$station)
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
names(merged0)
prestring =  "road|pop|temp|wind|rad|eleva|indu|trop|night"
varstring = paste0(prestring,y_var)
merged = data.frame(cbind(merged0%>%dplyr::select(y_var),  predictors))%>%na.omit()%>%unique()
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
names(merged)
nrow(merged)
Impor_val =  function(n,df, method , y_var  ) {
set.seed(n)
smp_size <- floor(0.8 * nrow(df))
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
methodID = switch(method,  "xboost"=1,"rf" =2, "gb"=3)
df = switch(methodID,
xgboost_imp (variabledf= df, y_varname= y_var, max_depth =3, gamma=1, eta =0.05, nthread = 4, nrounds = 200, training=training, test=test, grepstring =varstring ),
rf_imp(df, y_varname= y_var, training=training, test=test, grepstring =varstring,mtry = 24, numtrees = 1000),
Brt_imp (df, opti = F,   ntree= 2000, y_varname= y_var, training=training, test=test,  grepstring =varstring)
)
return(df)
}
Vxb = data.frame(lapply(1:20, Impor_val, df= merged, "xboost" , y_var =y_var))
merged
Vxb = data.frame(lapply(1:20, Impor_val, df= merged, "xboost" , y_var =y_var))
names(merged)
xgboost_imp
merged = merged0%>%subset_grep(varstring)%>%na.omit()%>%unique()
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
names(merged)
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
nrow(merged)
names(merged0)
varstring
prestring =  "road|pop|temp|wind|rad|eleva|indu|trop|night|"
varstring = paste0(prestring,y_var)
merged = merged0%>%subset_grep(varstring)%>%na.omit()%>%unique()
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
nrow(merged)
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
nanmes(merged)
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
names(merged)
set.seed(2)
smp_size = floor(0.9 * nrow(NLDE))
Impor_val =  function(n,df, method , y_var  ) {
set.seed(n)
smp_size <- floor(0.8 * nrow(df))
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
methodID = switch(method,  "xboost"=1,"rf" =2, "gb"=3)
df = switch(methodID,
xgboost_imp (variabledf= df, y_varname= y_var, max_depth =3, gamma=1, eta =0.05, nthread = 4, nrounds = 200, training=training, test=test, grepstring =varstring ),
rf_imp(df, y_varname= y_var, training=training, test=test, grepstring =varstring,mtry = 24, numtrees = 1000),
Brt_imp (df, opti = F,   ntree= 2000, y_varname= y_var, training=training, test=test,  grepstring =varstring)
)
return(df)
}
Vxb = data.frame(lapply(1:20, Impor_val, df= merged, "xboost" , y_var =y_var))
Impor_val =  function(n,df, method , y_var  ) {
set.seed(n)
smp_size <- floor(0.8 * nrow(df))
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
methodID = switch(method,  "xboost"=1,"rf" =2, "gb"=3)
df = switch(methodID,
xgboost_imp (variabledf= df, y_varname= y_var, max_depth =3, gamma=1, eta =0.05, nthread = 4, nrounds = 200, training=training, test=test, grepstring =varstring,xgb_lambda = 0,xgb_alpha = 0 ),
rf_imp(df, y_varname= y_var, training=training, test=test, grepstring =varstring,mtry = 24, numtrees = 1000),
Brt_imp (df, opti = F,   ntree= 2000, y_varname= y_var, training=training, test=test,  grepstring =varstring)
)
return(df)
}
Vxb = data.frame(lapply(1:20, Impor_val, df= merged, "xboost" , y_var =y_var))
Impor_val =  function(n,df, method , y_var  ) {
set.seed(n)
smp_size <- floor(0.8 * nrow(df))
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
methodID = switch(method,  "xboost"=1,"rf" =2, "gb"=3)
df = switch(methodID,
xgboost_imp (variabledf= df, y_varname= y_var, max_depth =3, gamma=1, eta =0.05, nthread = 4, nrounds = 200, training=training, test=test, grepstring =varstring,xgb_lambda = 0,xgb_alpha = 0 ),
rf_imp(df, y_varname= y_var, training=training, test=test, grepstring =varstring,mtry = 24, numtrees = 1000),
Brt_imp (df, opti = F,   ntree= 2000, y_varname= y_var, training=training, test=test,  grepstring =varstring)
)
return(df)
}
Vxb = data.frame(lapply(1:20, Impor_val, df= merged, "xboost" , y_var =y_var))
Impor_val =  function(n,df, method , y_var  ) {
set.seed(n)
smp_size <- floor(0.8 * nrow(df))
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
methodID = switch(method,  "xboost"=1,"rf" =2, "gb"=3)
df = switch(methodID,
xgboost_imp (variabledf= df, y_varname= y_var, max_depth =3, gamma=1, eta =0.05, nthread = 4, nrounds = 200, training=training, test=test, grepstring =varstring,xgb_lambda = 0,xgb_alpha = 0, subsample = 0.7),
rf_imp(df, y_varname= y_var, training=training, test=test, grepstring =varstring,mtry = 24, numtrees = 1000),
Brt_imp (df, opti = F,   ntree= 2000, y_varname= y_var, training=training, test=test,  grepstring =varstring)
)
return(df)
}
Vxb = data.frame(lapply(1:20, Impor_val, df= merged, "xboost" , y_var =y_var))
Vrf =  data.frame(lapply(1:20, Impor_val, df = merged, "rf" , y_var = y_var))
mimpVrf = apply(Vrf, 1, median)
mimpxb = apply(Vxb, 1, median)
xb = names(mimpxb[order(mimpxb,decreasing = T)]  )[1:20]
rf = names(mimpVrf[order(mimpVrf,decreasing = T)] ) [1:20]
vimp=cbind(rank = 1:20, xgboost = xb, randomforest = rf)
#install.packages("stargazer")
library(stargazer)
stargazer(vimp)
y_var = "mean_value"
# choose "value_mean for the mean of all hours, for different hours: X9_mean_value, X10_mean_value
sr =  stack("~/Documents/GitHub/nijmegen/predictorsmay20")
prestring =  "road|pop|temp|wind|rad|eleva|indu|trop|night|"
varstring = paste0(prestring,y_var)
predictors = read.csv ("~/Documents/GitHub/nijmegen/STATION_CSV_483/de_nl_predictors.csv",stringsAsFactors = F)
predictors <- as.data.frame(sapply(predictors, as.numeric))
# no2 measurements
value  = read.csv("~/Documents/Github/nijmegen/STATION_CSV_483/new_DENLjuly.csv", sep = ",")
value_mean = value%>%dplyr::select(X10_mean_value,X11_mean_value,X7_mean_value,X8_mean_value,X9_mean_value)%>%apply(1,mean)
value$mean_value = value_mean
summary(merged0)
#assign id and merge
value$id = 1:nrow(value)
merged0 = merge(value, predictors, by = "id")
#check
all.equal(merged0$lon.x,merged0$lon.y)
merged0%>%nrow()
# get the hourly value
merged = merged0%>%subset_grep(varstring)%>%na.omit()%>%unique()
# merge road types to form a new road type
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
names(merged)
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
names(merged)
y_var = "$mean_value"
# choose "value_mean for the mean of all hours, for different hours: X9_mean_value, X10_mean_value
sr =  stack("~/Documents/GitHub/nijmegen/predictorsmay20")
predictors = read.csv ("~/Documents/GitHub/nijmegen/STATION_CSV_483/de_nl_predictors.csv",stringsAsFactors = F)
predictors <- as.data.frame(sapply(predictors, as.numeric))
# no2 measurements
value  = read.csv("~/Documents/Github/nijmegen/STATION_CSV_483/new_DENLjuly.csv", sep = ",")
value_mean = value%>%dplyr::select(X10_mean_value,X11_mean_value,X7_mean_value,X8_mean_value,X9_mean_value)%>%apply(1,mean)
value$mean_value = value_mean
#assign id and merge
value$id = 1:nrow(value)
merged0 = merge(value, predictors, by = "id")
#check
all.equal(merged0$lon.x,merged0$lon.y)
merged0%>%nrow()
# get the hourly value
merged = merged0%>%subset_grep(varstring)%>%na.omit()%>%unique()
# merge road types to form a new road type
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
names(merged)
y_var = "value_mean"
# choose "value_mean for the mean of all hours, for different hours: X9_mean_value, X10_mean_value
sr =  stack("~/Documents/GitHub/nijmegen/predictorsmay20")
prestring =  "road|pop|temp|wind|rad|eleva|indu|trop|night|"
varstring = paste0(prestring,y_var)
predictors = read.csv ("~/Documents/GitHub/nijmegen/STATION_CSV_483/de_nl_predictors.csv",stringsAsFactors = F)
predictors <- as.data.frame(sapply(predictors, as.numeric))
# no2 measurements
value  = read.csv("~/Documents/Github/nijmegen/STATION_CSV_483/new_DENLjuly.csv", sep = ",")
value_mean = value%>%dplyr::select(X10_mean_value,X11_mean_value,X7_mean_value,X8_mean_value,X9_mean_value)%>%apply(1,mean)
value$value_mean = value_mean
#assign id and merge
value$id = 1:nrow(value)
merged0 = merge(value, predictors, by = "id")
#check
all.equal(merged0$lon.x,merged0$lon.y)
merged0%>%nrow()
# get the hourly value
merged = merged0%>%subset_grep(varstring)%>%na.omit()%>%unique()
# merge road types to form a new road type
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
names(merged)
Impor_val =  function(n,df, method , y_var  ) {
set.seed(n)
smp_size <- floor(0.8 * nrow(df))
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
methodID = switch(method,  "xboost"=1,"rf" =2, "gb"=3)
df = switch(methodID,
xgboost_imp (variabledf= df, y_varname= y_var, max_depth =3, gamma=1, eta =0.05, nthread = 4, nrounds = 200, training=training, test=test, grepstring =varstring,xgb_lambda = 0,xgb_alpha = 0, subsample = 0.7),
rf_imp(df, y_varname= y_var, training=training, test=test, grepstring =varstring,mtry = 24, numtrees = 1000),
Brt_imp (df, opti = F,   ntree= 2000, y_varname= y_var, training=training, test=test,  grepstring =varstring)
)
return(df)
}
Vxb = data.frame(lapply(1:20, Impor_val, df= merged, "xboost" , y_var =y_var))
Vrf =  data.frame(lapply(1:20, Impor_val, df = merged, "rf" , y_var = y_var))
mimpVrf = apply(Vrf, 1, median)
mimpxb = apply(Vxb, 1, median)
xb = names(mimpxb[order(mimpxb,decreasing = T)]  )[1:20]
rf = names(mimpVrf[order(mimpVrf,decreasing = T)] ) [1:20]
vimp=cbind(rank = 1:20, xgboost = xb, randomforest = rf)
#install.packages("stargazer")
library(stargazer)
stargazer(vimp)
#V2= c("P_LM_NO_OMI_day","P_LM_with_OMI_day","P_LM_night","P_Lasso_day","P_lasso_night", "P_rf_day","P_rf_night","P_ctree_day")
#for ( i in 1:10)
crossvali =  function(n,df, y_var) {
smp_size <- floor(0.8 * nrow(df))
set.seed(n)
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
P_rf = rf_LUR(df, numtrees =  1000, mtry = 14, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
P_xgb= xgboost_LUR(df, max_depth =3, gamma=1, eta =0.05, nthread = 20, xgb_lambda = 0,xgb_alpha = 0, subsample = 0.7, nrounds = 200, y_varname= y_var,training=training, test=test, grepstring =varstring)
P_Lasso =  Lasso(df,alpha =1 , vis1  = F,y_varname = y_var,training=training, test=test,grepstring =prestring )
V = cbind(P_rf, P_xgb, P_Lasso)
}
V2 = lapply(1:20, df = merged, y_var = y_var,crossvali)
V3 = data.frame(V2)
#save(V3, file = paste0("V3.rdata"))
V3
merged0 = merge(value, predictors, by = c("lat","lon")
merged0
merged0 = merge(value, predictors, by = c("lat","lon")
#check
all.equal(merged0$lon.x,merged0$lon.y)
merged0 = merge(value, predictors, by = c("lat","lon"))
predictors
predictors%>%rename(lon= "long")
predictors= predictors%>%rename(lon= "long")
merged0 = merge(value, predictors, by = c("lat","lon"))
#check
all.equal(merged0$lon.x,merged0$lon.y)
merged0%>%nrow()
merged = merged0%>%subset_grep(varstring)%>%na.omit()%>%unique()
# merged = mergedsp %>% dplyr::select(-lon,-lat.x)
names(merged)
Impor_val =  function(n,df, method , y_var  ) {
set.seed(n)
smp_size <- floor(0.8 * nrow(df))
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
methodID = switch(method,  "xboost"=1,"rf" =2, "gb"=3)
df = switch(methodID,
xgboost_imp (variabledf= df, y_varname= y_var, max_depth =3, gamma=1, eta =0.05, nthread = 4, nrounds = 200, training=training, test=test, grepstring =varstring,xgb_lambda = 0,xgb_alpha = 0, subsample = 0.7),
rf_imp(df, y_varname= y_var, training=training, test=test, grepstring =varstring,mtry = 24, numtrees = 1000),
Brt_imp (df, opti = F,   ntree= 2000, y_varname= y_var, training=training, test=test,  grepstring =varstring)
)
return(df)
}
Vxb = data.frame(lapply(1:20, Impor_val, df= merged, "xboost" , y_var =y_var))
Vrf =  data.frame(lapply(1:20, Impor_val, df = merged, "rf" , y_var = y_var))
mimpVrf = apply(Vrf, 1, median)
mimpxb = apply(Vxb, 1, median)
xb = names(mimpxb[order(mimpxb,decreasing = T)]  )[1:20]
rf = names(mimpVrf[order(mimpVrf,decreasing = T)] ) [1:20]
vimp=cbind(rank = 1:20, xgboost = xb, randomforest = rf)
#install.packages("stargazer")
library(stargazer)
stargazer(vimp)
#V2= c("P_LM_NO_OMI_day","P_LM_with_OMI_day","P_LM_night","P_Lasso_day","P_lasso_night", "P_rf_day","P_rf_night","P_ctree_day")
#for ( i in 1:10)
crossvali =  function(n,df, y_var) {
smp_size <- floor(0.8 * nrow(df))
set.seed(n)
training<- sample(seq_len(nrow(df)), size = smp_size)
test = seq_len(nrow(df))[-training]
P_rf = rf_LUR(df, numtrees =  1000, mtry = 14, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
P_xgb= xgboost_LUR(df, max_depth =3, gamma=1, eta =0.05, nthread = 20, xgb_lambda = 0,xgb_alpha = 0, subsample = 0.7, nrounds = 200, y_varname= y_var,training=training, test=test, grepstring =varstring)
P_Lasso =  Lasso(df,alpha =1 , vis1  = F,y_varname = y_var,training=training, test=test,grepstring =prestring )
V = cbind(P_rf, P_xgb, P_Lasso)
}
V2 = lapply(1:20, df = merged, y_var = y_var,crossvali)
V3 = data.frame(V2)
#save(V3, file = paste0("V3.rdata"))
V3
rf_imp()
rf_imp
#library(RColorBrewer)
nvaria = ncol(V2[[1]])
F1 = function(m, f=quote(summary)) {  apply(V3[, seq(m,ncol(V3), by =nvaria)], 1, f) }
plotresult = function(m0, DorN = c("mean of 20 times")){
m1 = melt(t(m0))
ggplot(m1, aes(Var2, value))+ geom_bar(stat = "identity",aes(fill = Var1),position = "dodge")+
xlab("methods") + ylab("Accuracy") +
ggtitle(paste0("bootstrap sub-sampling cross-validation: ", DorN)) +
theme_bw()+theme(axis.text=element_text(size=15),legend.text=element_text(size=20),axis.title=element_text(size=15,face="bold"))+
scale_fill_brewer(palette="Set2")  + theme(legend.title = element_blank())
}
library(stargazer)
meanvali = data.frame(sapply(1:nvaria, F1,  mean))
names( meanvali) = dimnames(V2[[1]])[[2]]
m0 = data.frame(t(meanvali))
row.names(m0) = c(  "XGB", "RF", "Lasso")
#m0$type1 = c(rep("day", 6), rep("night",5))
m0
stargazer(t(m0))
plotresult(m0)
stargazer(m0, digits = 2)
stargazer(t(m0), digits = 2, summary = F)
stargazer(m0, digits = 2, summary = F)
m0
m1 = m0%>%dplyr::select(RMSE, IQR, MAE, rsq)
stargazer(m1, digits = 2, summary = F)
xgb_pre
library(sf)
library(spData)
library(spDataLarge)
data(world)
names(world)
plot(world[,2])
plot(world[1:2,2])
world_asia = world[world$continent == "Asia", ]
asia = st_union(world_asia)
#Plots are added as layers to existing images by setting add = TRUE
plot(world["pop"], reset = FALSE)
#A legend or ‘key’ with a continuous color is produced if the object to be plotted has a single variable.
#Note that the first plot must only have one facet for add = TRUE to work.
#If the first plot has a key, reset = FALSE must be used.
plot(asia, add = TRUE, col = "red")
plot(a7$road_class_M345_25, glo4var$road_class_3_25)
aall = read.csv("~/Documents/GitHub/Global mapping/glo4var_sfroad.csv")
#write.csv(a , "~/Documents/GitHub/Global mapping/glo4var_sfroad.csv")
#write.csv(a, paste0(dirout, "glo4var_sfroad.csv"))
#a7 = a7%>%dplyr::select(-X)
a7 = merge_roads(aall, c(3,4,5),keep = F)
data("glo4var")
cor(a7$road_class_M345_25, glo4var$road_class_3_25)
plot(a7$road_class_M345_25, glo4var$road_class_3_25)
plot(a7$road_class_M345_25, glo4var$road_class_3_25)
#a$NO2 = glo4var$wkd_day_value
dev.off()
plot(a7$road_class_M345_25, glo4var$road_class_3_25)

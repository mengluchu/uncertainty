rrf_mean
as.vector(predictions(mean_reg))
rrf_sd
error_matrix(y_denl_test,rrf_mean)
error_matrix(y_denl_test,predict(RF,x_p[test,],type = "response")%>%predictions)
distcrps
regcrps
distcrps
y_denl_test
distcrps
rrfcrps
cbind(distcrps,rrfcrps,regcrps)
summary(  cbind(distcrps,rrfcrps,regcrps))
allp = predict(RF,x_p[training,],type = "terminalNodes")
allp
allp = predict(RF,x_p[training,],type = "terminalNodes")$predictions
allp
max(allp)
dim(allp)
allp[,1]
max(allp[,1])
max(allp[,12)
max(allp[,12])
max(allp[,2])
allp[,1]
summary(allp[,1])
summary(allp[,2])
summary(allp[,3])
summary(allp[,4])
summary(allp[,5])
table(allp[,5])
unique(allp[,5])
table(allp[,2])
length(allp[,2])
#################################
RF <- ranger(x = x_p[training,],
y = y_denl[training], mtry = NULL, num.trees = 1000,quantreg=TRUE,min.node.size = 10)
allp = predict(RF,x_p[training,],type = "terminalNodes")$predictions
max(allp)
table(allp[,1])
table(allp[,2])
dim(reduced_rf)
#################################
RF <- ranger(x = x_p[training,],
y = y_denl[training], mtry = NULL, num.trees = 1000,min.node.size = 10)
allp = predict(RF,x_p[training,],type = "terminalNodes")$predictions
table(allp[,2])
table(allp[,20])
table(allp[1,])
RF
str(RF)
table(allp[1,])
length(unique(allp[,1]))
length(unique(allp[,2]))
length(unique(allp[,4]))
length(unique(allp[,3]))
length(unique(allp[,30]))
length(unique(allp[,32]))
length(unique(allp[,39]))
#################################
RF <- ranger(x = x_p[training,],
y = y_denl[training], mtry = NULL, num.trees = 1000,min.node.size = 20)
length(unique(allp[,39]))
allp = predict(RF,x_p[training,],type = "terminalNodes")$predictions
length(unique(allp[,39]))
dim(reduced_rf)
allp = predict(RF,x_p[training,],type = "response", predict.all = T)%>%predictions #get all the tree predictions, instead of the mean
dim(allp)
cvfit <- glmnet::cv.glmnet(allp,y_denl[training],
type.measure = "mse", standardize = TRUE, alpha = 1,
lower.limit = 0)
# aggregate using a regularization, here lasso, you can also do elastic net, training alpha or specify alpha between 0 and 1
print(sum(coef(cvfit)[-1]!= 0))
cvfit
summary(cvfit)
str(cvfit)
dim(allp)
?glmnet::cv.glmnet
length(training)
cvfit <- glmnet::cv.glmnet(allp,y_denl[training],
type.measure = "mse", standardize = TRUE, alpha = 1,
lower.limit = 0, nfolds = 5)
str(cvfit)
cvfit <- glmnet::cv.glmnet(allp,y_denl[training],
type.measure = "mse", standardize = TRUE, alpha = 1,
lower.limit = 0, nfolds = 15)
str(cvfit)
rpre= predict(RF,x_p[test,], predict.all=T)%>%predictions # get all the tree predictions
reduced_rf = rpre[,Ls_num]
num.trees = 1000
terminal.nodes <- predict(RF, x_p[test,], type = "terminalNodes")$predictions + 1
random.node.values <- matrix(nrow = max(terminal.nodes), ncol = num.trees)
## Select one random obs per node and tree
for (tree in 1:num.trees){
idx <- sample(1:n, n)
result$random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_test[idx]
## Select one random obs per node and tree
for (tree in 1:num.trees){
idx <- sample(1:n, n)
result$random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_test[idx]
}
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_test[idx]
}
random.node.values
n <- length(test)
rpre= predict(RF,x_p[test,], predict.all=T)%>%predictions # get all the tree predictions
reduced_rf = rpre[,Ls_num]
num.trees = 1000
terminal.nodes <- predict(RF, x_p[test,], type = "terminalNodes")$predictions + 1
random.node.values <- matrix(nrow = max(terminal.nodes), ncol = num.trees)
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_test[idx]
}
random.node.values
y_denl_test
idx
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_test[idx]
}
random.node.values
terminal.nodes[idx, tree]
rrf_u90 <- t(apply(node.values, 1, quantile, 0.95, na.rm=TRUE))
for (tree in 1:num.trees) {
node.values[, tree] <-  random.node.values[terminal.nodes[, tree], tree]
}
node.values <- 0 * terminal.nodes
for (tree in 1:num.trees) {
node.values[, tree] <-  random.node.values[terminal.nodes[, tree], tree]
}
node.values
rrf_u90 <- t(apply(node.values, 1, quantile, 0.95, na.rm=TRUE))
pred.distribution$predictions[, "quantile= 0.05"],
pred.distribution$predictions[, "quantile= 0.95"]
rrf_u90
y_denl_train = y_denl[training]
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_train[idx]
## Select one random obs per node and tree
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_train[idx]
}
n <- length(test)
rpre= predict(RF,x_p[test,], predict.all=T)%>%predictions # get all the tree predictions
reduced_rf = rpre[,Ls_num]
num.trees = 1000
y_denl_train = y_denl[training]
terminal.nodes <- predict(RF, x_p[training,], type = "terminalNodes")$predictions + 1
random.node.values <- matrix(nrow = max(terminal.nodes), ncol = num.trees)
## Select one random obs per node and tree
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_train[idx]
}
terminal.nodes <- predict(object, data, type = "terminalNodes")$predictions + 1
terminal.nodes <- predict(RF, x_p[test,], type = "terminalNodes")$predictions + 1
node.values <- 0 * terminal.nodes
for (tree in 1:num.trees) {
node.values[, tree] <-  random.node.values[terminal.nodes[, tree], tree]
}
rrf_u90 <- t(apply(node.values, 1, quantile, 0.95, na.rm=TRUE))
rrf_u90
pred.distribution$predictions[, "quantile= 0.05"],
plot(y_denl[training], pred.distribution$predictions[, "quantile= 0.95"])
pred.distribution$predictions[, "quantile= 0.05"],
plot(rrf_u90 , pred.distribution$predictions[, "quantile= 0.95"])
abline(b= 1, a =0)
dim(node.values)
dim(random.node.values)
max(terminal.nodes)
length(test)
Ls_num= as.vector(sapply(Ls, function(x) as.numeric(substr(x, start =2, stop = nchar(x)))))
n <- length(test)
rpre= predict(RF,x_p[test,], predict.all=T)%>%predictions # get all the tree predictions
reduced_rf = rpre[,Ls_num]
num.trees = 1000
y_denl_train = y_denl[training]
terminal.nodes <- predict(RF, x_p[training,], type = "terminalNodes")$predictions + 1
random.node.values <- matrix(nrow = max(terminal.nodes), ncol = num.trees)
dim(terminal.nodes)
dim(random.node.values)
max(terminal.nodes)
terminal.nodes
terminal.nodes[,1]
table(terminal.nodes[,1] )
length(table(terminal.nodes[,1] ))
#################################
RF <- ranger(x = x_p[training,],
y = y_denl[training], mtry = NULL, num.trees = 1000, min.node.size = 10)
terminal.nodes <- predict(RF, x_p[training,], type = "terminalNodes")$predictions + 1
random.node.values <- matrix(nrow = max(terminal.nodes), ncol = num.trees)
dim(random.node.values)
max(terminal.nodes)
## Select one random obs per node and tree
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_train[idx]
}
random.node.values
terminal.nodes <- predict(RF, x_p[test,], type = "terminalNodes")$predictions + 1
node.values <- 0 * terminal.nodes
for (tree in 1:num.trees) {
node.values[, tree] <-  random.node.values[terminal.nodes[, tree], tree]
}
node.values
dim(node.values)
terminal.nodes
max(terminal.nodes)
dim(terminal.nodes)
rrf_u90 <- t(apply(node.values, 1, quantile, 0.95, na.rm=TRUE))
pred.distribution$predictions[, "quantile= 0.05"],
plot(rrf_u90 , pred.distribution$predictions[, "quantile= 0.95"])
abline(b= 1, a =0)
pred.distribution <- predict(quantRF,
data = x_p[test,],
type = "quantiles",
quantiles = seq(0.01, 0.99, by = 0.01))
sd_reg<- predict(quantRF,
data = x_p[test,],type = "quantiles",what=sd)
mean_reg <- predict(quantRF,
data = x_p[test,], type = "quantiles",what=mean)
#hist(pred.distribution$predictions[5,])
t.quant90 <- cbind(
pred.distribution$predictions[, "quantile= 0.05"],
pred.distribution$predictions[, "quantile= 0.95"])
pred.distribution$predictions[, "quantile= 0.05"],
plot(rrf_u90 , pred.distribution$predictions[, "quantile= 0.95"])
rrf_u90
dim(node.values)
apply(rpre, 1, quantile, 0.95)
rrf_u90 <-  apply(node.values, 1, quantile, 0.95, na.rm=TRUE)
rrf_u90
pred.distribution$predictions[, "quantile= 0.95"]
pred.distribution$predictions[, "quantile= 0.05"],
plot(rpre, pred.distribution$predictions[, "quantile= 0.95"])
pred.distribution$predictions[, "quantile= 0.05"],
plot(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
abline(b= 1, a =0)
pred.distribution$predictions[, "quantile= 0.05"],
cor(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
cor(rrf_u90, pred.distribution$predictions[, "quantile= 0.95"])
cor(rrf_u90, apply(rpre, 1, quantile, 0.95))
cor(rrf_u90, pred.distribution$predictions[, "quantile= 0.95"])
pred.distribution$predictions[, "quantile= 0.05"],
cor(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
sample(1:10, 10)
terminal.nodes[1,1]
num.trees = 1000
y_denl_train = y_denl[training]
terminal.nodes <- predict(RF, x_p[training,], type = "terminalNodes")$predictions + 1
random.node.values <- matrix(nrow = max(terminal.nodes), ncol = num.trees)
## Select one random obs per node and tree
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_train[idx]
}
dim(random.node.values)
image(random.node.values)
random.node.values
random.node.values[2,]
random.node.values[3,]
random.node.values[4,]
random.node.values[40,]
image(node.values)
RF <- ranger(x = x_p[training,],
y = y_denl[training], mtry = NULL, num.trees = 1000, min.node.size = 5)
allp = predict(RF,x_p[training,],type = "response", predict.all = T)%>%predictions #get all the tree predictions, instead of the mean
#dim(allp2)
#allp = predict(RF,x_p[training,],type = "terminalNodes")$predictions
# length(unique(allp[,39]))
#plot(  apply(allp, 1, quantile, 0.05),pred.distribution$predictions[, "quantile= 0.05"])
#apply(allp, 1, quantile, 0.95)-pred.distribution$predictions[, "quantile= 0.95"]
#plot(  apply(allp, 1, quantile, 0.95),pred.distribution$predictions[, "quantile= 0.95"], col = "red")
#abline(a=0,b = 1)
cvfit <- glmnet::cv.glmnet(allp,y_denl[training],
type.measure = "mse", standardize = TRUE, alpha = 1,
lower.limit = 0, nfolds = 10)
# aggregate using a regularization, here lasso, you can also do elastic net, training alpha or specify alpha between 0 and 1
print(sum(coef(cvfit)[-1]!= 0))
# we can also plot it, using a tool from APMtools
Ls= Lassoselected(cvfit)
Ls_num= as.vector(sapply(Ls, function(x) as.numeric(substr(x, start =2, stop = nchar(x)))))
n <- length(test)
rpre= predict(RF,x_p[test,], predict.all=T)%>%predictions # get all the tree predictions
reduced_rf = rpre[,Ls_num]
y_denl_train = y_denl[training]
###############somehow i get different quantiles, using the same method. I dont know why it does not cauculate quantiles from predict.all =T, they are closely correlated, but not equal, i guess it is becaue of the random.node, why does it do it? ###########################################
### try the original quantile rf
num.trees = 1000
y_denl_train = y_denl[training]
terminal.nodes <- predict(RF, x_p[training,], type = "terminalNodes")$predictions + 1
random.node.values <- matrix(nrow = max(terminal.nodes), ncol = num.trees)
## Select one random obs per node and tree
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_train[idx]
}
terminal.nodes <- predict(RF, x_p[test,], type = "terminalNodes")$predictions + 1
node.values <- 0 * terminal.nodes
for (tree in 1:num.trees) {
node.values[, tree] <-  random.node.values[terminal.nodes[, tree], tree]
}
rrf_u90 <-  apply(node.values, 1, quantile, 0.95, na.rm=TRUE)
#########################################################################
apply(rpre, 1, quantile, 0.95)
pred.distribution$predictions[, "quantile= 0.05"],
cor(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
cor(rrf_u90, pred.distribution$predictions[, "quantile= 0.95"])
cor(rrf_u90, apply(rpre, 1, quantile, 0.95))
abline(b= 1, a =0)
plot(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
plot(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
abline(b= 1, a =0)
quantRF <- ranger(x = x_p[training,],
y = y_denl[training], mtry = NULL, num.trees = 1000,
quantreg = T, min.node.size = 10)
pred.distribution <- predict(quantRF,
data = x_p[test,],
type = "quantiles",
quantiles = seq(0.01, 0.99, by = 0.01))
sd_reg<- predict(quantRF,
data = x_p[test,],type = "quantiles",what=sd)
mean_reg <- predict(quantRF,
data = x_p[test,], type = "quantiles",what=mean)
plot(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
abline(b= 1, a =0)
pred.distribution$predictions[, "quantile= 0.05"],
cor(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
#################################
RF <- ranger(x = x_p[training,],
y = y_denl[training], mtry = NULL, num.trees = 1000, min.node.size = 10)
allp = predict(RF,x_p[training,],type = "response", predict.all = T)%>%predictions #get all the tree predictions, instead of the mean
plot(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
abline(b= 1, a =0)
RF <- ranger(x = x_p[training,],
y = y_denl[training], mtry = NULL, num.trees = 1000, min.node.size = 10)
allp = predict(RF,x_p[training,],type = "response", predict.all = T)%>%predictions #get all the tree predictions, instead of the mean
#dim(allp2)
#allp = predict(RF,x_p[training,],type = "terminalNodes")$predictions
# length(unique(allp[,39]))
#plot(  apply(allp, 1, quantile, 0.05),pred.distribution$predictions[, "quantile= 0.05"])
#apply(allp, 1, quantile, 0.95)-pred.distribution$predictions[, "quantile= 0.95"]
#plot(  apply(allp, 1, quantile, 0.95),pred.distribution$predictions[, "quantile= 0.95"], col = "red")
#abline(a=0,b = 1)
cvfit <- glmnet::cv.glmnet(allp,y_denl[training],
type.measure = "mse", standardize = TRUE, alpha = 1,
lower.limit = 0, nfolds = 10)
# aggregate using a regularization, here lasso, you can also do elastic net, training alpha or specify alpha between 0 and 1
print(sum(coef(cvfit)[-1]!= 0))
# we can also plot it, using a tool from APMtools
Ls= Lassoselected(cvfit)
Ls_num= as.vector(sapply(Ls, function(x) as.numeric(substr(x, start =2, stop = nchar(x)))))
n <- length(test)
rpre= predict(RF,x_p[test,], predict.all=T)%>%predictions # get all the tree predictions
reduced_rf = rpre[,Ls_num]
y_denl_train = y_denl[training]
###############somehow i get different quantiles, using the same method. I dont know why it does not cauculate quantiles from predict.all =T, they are closely correlated, but not equal, i guess it is becaue of the random.node, why does it do it? ###########################################
### try the original quantile rf
num.trees = 1000
y_denl_train = y_denl[training]
terminal.nodes <- predict(RF, x_p[training,], type = "terminalNodes")$predictions + 1
random.node.values <- matrix(nrow = max(terminal.nodes), ncol = num.trees)
## Select one random obs per node and tree
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_train[idx]
}
terminal.nodes <- predict(RF, x_p[test,], type = "terminalNodes")$predictions + 1
node.values <- 0 * terminal.nodes
for (tree in 1:num.trees) {
node.values[, tree] <-  random.node.values[terminal.nodes[, tree], tree]
}
rrf_u90 <-  apply(node.values, 1, quantile, 0.95, na.rm=TRUE)
#########################################################################
apply(rpre, 1, quantile, 0.95)
pred.distribution$predictions[, "quantile= 0.05"],
cor(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
cor(rrf_u90, pred.distribution$predictions[, "quantile= 0.95"])
cor(rrf_u90, apply(rpre, 1, quantile, 0.95))
plot(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
abline(b= 1, a =0)
num.trees = 1000
y_denl_train = y_denl[training]
terminal.nodes <- predict(RF, x_p[training,], type = "terminalNodes")$predictions
random.node.values <- matrix(nrow = max(terminal.nodes), ncol = num.trees)
## Select one random obs per node and tree
for (tree in 1:num.trees){
idx <- sample(1:n, n)
random.node.values[terminal.nodes[idx, tree], tree] <- y_denl_train[idx]
}
terminal.nodes <- predict(RF, x_p[test,], type = "terminalNodes")$predictions
node.values <- 0 * terminal.nodes
for (tree in 1:num.trees) {
node.values[, tree] <-  random.node.values[terminal.nodes[, tree], tree]
}
rrf_u90 <-  apply(node.values, 1, quantile, 0.95, na.rm=TRUE)
#########################################################################
apply(rpre, 1, quantile, 0.95)
pred.distribution$predictions[, "quantile= 0.05"],
cor(apply(rpre, 1, quantile, 0.95), pred.distribution$predictions[, "quantile= 0.95"])
cor(rrf_u90, pred.distribution$predictions[, "quantile= 0.95"])
cor(rrf_u90, apply(rpre, 1, quantile, 0.95))
cor(rf_u90, pred.distribution$predictions[, "quantile= 0.95"])
rf_u90 <-  apply(node.values, 1, quantile, 0.95, na.rm=TRUE)
cor(rf_u90, pred.distribution$predictions[, "quantile= 0.95"])
cor(rf_u90, apply(rpre, 1, quantile, 0.95))
rrf_u90 = apply(reduced_rf, 1, quantile, 0.95)
rrf_l90 = apply(reduced_rf, 1, quantile, 0.05)
rrf_mean = apply(reduced_rf, 1,  mean)
rrf_sd= apply(reduced_rf, 1,   sd)
error_matrix(y_denl_test,rrf_mean)
error_matrix(y_denl_test,predict(RF,x_p[test,],type = "response")%>%predictions)
rrf_sd
rrfcrps = crps(y = y_denl_test, family = "norm", mean = rrf_mean, sd = rrf_sd)
summary(  cbind(distcrps,rrfcrps,regcrps))
dim(allp)
rrf2_u90 = apply(node.values[,Ls_num], 1, quantile, 0.95)
rrf2_l90 = apply(node.values[,Ls_num], 1, quantile, 0.05,na.rm=TRUE)
rrf2_u90 = apply(node.values[,Ls_num], 1, quantile, 0.95,na.rm=TRUE)
rrf2_l90 - rrf_l90
plot(rrf2_l90, rrf_l90)
df1 = cbind(data.frame(rf_90), data.frame(dist.q90), rrf2_l90,rrf2_u90,id = 1:nrow(data.frame(rf_90)),y_denl_test )
names(df1) = c("quantile_RF_L90","quantile_RF_U90", "Distribution_RF_L90","Distribution_RF_U90", "reduced_RF_L90","reduced_RF_U90", "id", "test")
df1 = df1%>%  gather(variable, value, -id, -test, -quantile_RF_L90, -quantile_RF_U90)
ggplot(df1)+aes(x = id, y = value, colour = variable)+geom_line()+
geom_point(aes(y=test), colour= "black")+
scale_color_brewer(palette="Spectral")+labs(x = "test points", y = "NO2", colour = "prediction intervals")
names(df1) = c("quantile_RF_L90","quantile_RF_U90", "Distribution_RF_L90","Distribution_RF_U90", "reduced_RF_L90","reduced_RF_U90", "reduced2_RF_L90","reduced2_RF_U90","id", "test")
#plot(inla_90[,1], ylim = c(min(y_denl_test)-1,max(y_denl_test)+1), col = "red", typ = "l")
df1 = cbind(data.frame(rf_90), data.frame(dist.q90), rrf_l90,rrf_u90,rrf2_l90,rrf2_u90,id = 1:nrow(data.frame(rf_90)),y_denl_test )
names(df1) = c("quantile_RF_L90","quantile_RF_U90", "Distribution_RF_L90","Distribution_RF_U90", "reduced_RF_L90","reduced_RF_U90", "reduced2_RF_L90","reduced2_RF_U90","id", "test")
df1 = df1%>%  gather(variable, value, -id, -test, -quantile_RF_L90, -quantile_RF_U90)
df1 = df1%>%  gather(variable, value, -id, -test, -quantile_RF_L90, -quantile_RF_U90, -Distribution_RF_L90, -Distribution_RF_U90)
df1 = cbind(data.frame(rf_90), data.frame(dist.q90), rrf_l90,rrf_u90,rrf2_l90,rrf2_u90,id = 1:nrow(data.frame(rf_90)),y_denl_test )
names(df1) = c("quantile_RF_L90","quantile_RF_U90", "Distribution_RF_L90","Distribution_RF_U90", "reduced_RF_L90","reduced_RF_U90", "reduced2_RF_L90","reduced2_RF_U90","id", "test")
df1 = df1%>%  gather(variable, value, -id, -test, -quantile_RF_L90, -quantile_RF_U90, -Distribution_RF_L90, -Distribution_RF_U90)
ggplot(df1)+aes(x = id, y = value, colour = variable)+geom_line()+
geom_point(aes(y=test), colour= "black")+
scale_color_brewer(palette="Spectral")+labs(x = "test points", y = "NO2", colour = "prediction intervals")
rrf2_mean = apply(node.values[,Ls_num], 1, quantile, 0.5,na.rm=TRUE)
rrf2_sd = apply(node.values[,Ls_num], 1, sd ,na.rm=TRUE)
rrf2crps = crps(y = y_denl_test, family = "norm", mean = rrf2_mean, sd = rrf2_sd)
summary(  cbind(distcrps,rrfcrps,regcrps, rrf2crps))
error_matrix(y_denl_test,rrf2_mean)
error_matrix(y_denl_test,rrf_mean)
rrf2_mean = apply(node.values[,Ls_num], 1, mean,na.rm=TRUE)
error_matrix(y_denl_test,rrf2_mean)
error_matrix(y_denl_test,rrf_mean)
error_matrix(y_denl_test,predict(RF,x_p[test,],type = "response")%>%predictions)
rrfcrps = crps(y = y_denl_test, family = "norm", mean = rrf_mean, sd = rrf_sd)
rrf2crps = crps(y = y_denl_test, family = "norm", mean = rrf2_mean, sd = rrf2_sd)
regcrps = crps(y = y_denl_test, family = "norm", mean = as.vector(predictions(mean_reg)), sd =as.vector(sd_reg$predictions))
summary(  cbind(distcrps,rrfcrps,regcrps, rrf2crps))
rrf2_mean
rrf2_sd
rrf_mean
rrf_sd
qrf <- quantregForest(x=x_p[training,],
y = y_denl[training], nodesize=10)
## predict 0.1, 0.5 and 0.9 quantiles for test data
conditionalQuantiles <- predict(qrf, x_p[test,], what = 0.95)
conditionalQuantiles -pred.distribution$predictions[, "quantile= 0.95"]
cor( conditionalQuantiles,pred.distribution$predictions[, "quantile= 0.95"])
quantRF <- ranger(x = x_p[training,],
y = y_denl[training], mtry = NULL, num.trees = 1000,
quantreg = T, min.node.size = 10)
# compute predictions (mean) for each validation site
pred <- predict(quantRF, data = x_p[test,], what = mean)
## predict 0.01, 0.02,..., 0.99 quantiles for validation data
pred.distribution <- predict(quantRF,
data = x_p[test,],
type = "quantiles",
quantiles = seq(0.01, 0.99, by = 0.01))
## predict 0.1, 0.5 and 0.9 quantiles for test data
conditionalQuantiles <- predict(qrf, x_p[test,], what = 0.95, num.trees=1000)
qrf <- quantregForest(x=x_p[training,],
y = y_denl[training], nodesize=10, num.trees=1000)
## predict 0.1, 0.5 and 0.9 quantiles for test data
conditionalQuantiles <- predict(qrf, x_p[test,], what = 0.95)
cor( conditionalQuantiles,pred.distribution$predictions[, "quantile= 0.95"])
qrf <- quantregForest(x=x_p[training,],
y = y_denl[training], nodesize=10, num.trees=1000)
## predict 0.1, 0.5 and 0.9 quantiles for test data
conditionalQuantiles <- predict(qrf, x_p[test,], what = 0.95)
cor( conditionalQuantiles,pred.distribution$predictions[, "quantile= 0.95"])
qrf <- quantregForest(x=x_p[training,],
y = y_denl[training], nodesize=10, ntrees=1000)
## predict 0.1, 0.5 and 0.9 quantiles for test data
conditionalQuantiles <- predict(qrf, x_p[test,], what = 0.95)
cor( conditionalQuantiles,pred.distribution$predictions[, "quantile= 0.95"])
plot( conditionalQuantiles,pred.distribution$predictions[, "quantile= 0.95"])
QRF_U90 <- predict(qrf, x_p[test,], what = 0.95)
QRF_L90 <- predict(qrf, x_p[test,], what = 0.05)
#plot(inla_90[,1], ylim = c(min(y_denl_test)-1,max(y_denl_test)+1), col = "red", typ = "l")
df1 = cbind(data.frame(rf_90), data.frame(dist.q90), rrf_l90,rrf_u90,QRF_L90,QRF_L90,id = 1:nrow(data.frame(rf_90)),y_denl_test )
#plot(inla_90[,1], ylim = c(min(y_denl_test)-1,max(y_denl_test)+1), col = "red", typ = "l")
df1 = cbind(data.frame(rf_90), data.frame(dist.q90), rrf_l90,rrf_u90,QRF_L90,QRF_U90,id = 1:nrow(data.frame(rf_90)),y_denl_test )
names(df1) = c("quantile_RF_L90","quantile_RF_U90", "Distribution_RF_L90","Distribution_RF_U90", "reduced_RF_L90","reduced_RF_U90", "reduced2_RF_L90","reduced2_RF_U90","id", "test")
df1 = df1%>%  gather(variable, value, -id, -test, -quantile_RF_L90, -quantile_RF_U90, -Distribution_RF_L90, -Distribution_RF_U90)
ggplot(df1)+aes(x = id, y = value, colour = variable)+geom_line()+
geom_point(aes(y=test), colour= "black")+
scale_color_brewer(palette="Spectral")+labs(x = "test points", y = "NO2", colour = "prediction intervals")
df1 = cbind(data.frame(rf_90), data.frame(dist.q90), rrf_l90,rrf_u90,QRF_L90,QRF_U90,id = 1:nrow(data.frame(rf_90)),y_denl_test )
names(df1) = c("quantile_RF_L90","quantile_RF_U90", "Distribution_RF_L90","Distribution_RF_U90", "reduced_RF_L90","reduced_RF_U90", "reduced2_RF_L90","reduced2_RF_U90","id", "test")
df1 = df1%>%  gather(variable, value, -id, -test,  -Distribution_RF_L90, -Distribution_RF_U90)
ggplot(df1)+aes(x = id, y = value, colour = variable)+geom_line()+
geom_point(aes(y=test), colour= "black")+
scale_color_brewer(palette="Spectral")+labs(x = "test points", y = "NO2", colour = "prediction intervals")
#l
